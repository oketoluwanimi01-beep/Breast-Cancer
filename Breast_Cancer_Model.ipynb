{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPTRXreFMhg61oXdkC8TNQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heisarafat/Breast-Cancer/blob/main/Breast_Cancer_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tn6R6nopMnJw"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import shap\n",
        "import gradio as gr\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bc = pd.read_csv('breast-cancer.csv')"
      ],
      "metadata": {
        "id": "l4ExS6zCM4pQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "bi--2F75NBu9",
        "outputId": "f794525e-a2f8-405a-b649-2e84a00b21b5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See all column names\n",
        "print(bc.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zus_Ndg3NDPx",
        "outputId": "a0416e24-ad58-4e21-9da2-85025ae23870"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview\n",
        "print(bc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF3t__0JNR8c",
        "outputId": "84d6dc24-1092-4e0c-ce54-da97ab023509"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values\n",
        "print(bc.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPBXqkPINYPP",
        "outputId": "1524c7d7-8682-4fc6-a9e9-5da1a1accbd3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 'id' since it's not useful\n",
        "bc.drop(columns=['id'], inplace=True)"
      ],
      "metadata": {
        "id": "3FT0jLumNcJv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unique values in each column\n",
        "print(bc.nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG4DLwZnNgLk",
        "outputId": "8f288ca5-008b-457b-daeb-77ddba15242a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "# Class distribution\n",
        "sns.countplot(x='diagnosis', data=bc)\n",
        "plt.xticks([0,1], ['Benign', 'Malignant'])\n",
        "plt.title('Class Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "xZI_USBANkGu",
        "outputId": "902a3071-905f-498e-f6c6-095e6e59ce2b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical Summary\n",
        "bc.describe().T  # Transpose for readability"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "ZGgMfm8nOCYu",
        "outputId": "c735dd1c-0720-4bd8-dbfb-ebe1494f3f0f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode target\n",
        "bc['diagnosis'] = bc['diagnosis'].map({'M': 1, 'B': 0})"
      ],
      "metadata": {
        "id": "ATzGkgeFOTd2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation with Target\n",
        "corr_matrix = bc.corr()\n",
        "target_corr = corr_matrix['diagnosis'].sort_values(ascending=False)\n",
        "print(target_corr.head(10))  # Top positively correlated\n",
        "print(target_corr.tail(10))  # Most negative correlated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxJo5cmiOa5P",
        "outputId": "1630e0ea-c145-4f0b-e6f1-f201267e351d"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The correlation analysis shows that concave points_worst (0.79), perimeter_worst (0.78), and concave points_mean (0.78) have the strongest positive relationships with the diagnosis, indicating they are highly associated with malignancy.\n",
        "Conversely, features such as smoothness_se (-0.067) and fractal_dimension_mean (-0.013) show very weak or negative correlation, suggesting minimal predictive power for the target variable."
      ],
      "metadata": {
        "id": "dmseRoZZOl37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Top Features\n",
        "top_features = target_corr.index[1:6]  # Skip diagnosis itself\n",
        "for col in top_features:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.kdeplot(data=bc, x=col, hue='diagnosis', fill=True)\n",
        "    plt.title(f'{col} Distribution by Diagnosis')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eYx0cIKOOicM",
        "outputId": "4c3635e7-cd47-4b70-9932-0f5c0eb9b5b9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(corr_matrix, cmap='coolwarm')\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mwCD8jq0OudI",
        "outputId": "aeeb5d55-f8bd-4072-e8a3-f13427212b46"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The heatmap reveals how each feature relates both to other predictors and to the target variable diagnosis. Features such as concave points_worst, perimeter_worst, radius_worst, and area_worst exhibit strong positive correlations with the diagnosis label, meaning higher values of these measurements are strongly associated with malignant tumors. Conversely, features like smoothness_se and fractal_dimension_mean show little to no correlation with the diagnosis, suggesting they contribute less predictive power on their own."
      ],
      "metadata": {
        "id": "XdnIYo-gO3Y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "D082HT9tO5el"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To prepare the dataset for modeling, the target variable diagnosis was label-encoded, mapping Malignant (M) to 1 and Benign (B) to 0. Features were then examined for correlation with the target, revealing that variables such as concave points_worst, perimeter_worst, and radius_worst had the strongest positive associations, while features like smoothness_se and fractal_dimension_mean showed weak correlations. This informed later feature selection considerations to reduce redundancy from highly intercorrelated predictors. Finally, feature scaling was applied using StandardScaler to normalize the numerical variables, ensuring uniform influence in the training of machine learning models."
      ],
      "metadata": {
        "id": "m10TP6vKO-66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "x = bc.drop(columns=['diagnosis'])\n",
        "y = bc['diagnosis']  # target variable"
      ],
      "metadata": {
        "id": "nLu-Rv_zOzOB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data: 80% train, 20% test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train Shape:\", x_train.shape, y_train.shape)\n",
        "print(\"Test shape:\", x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BKmGT-TPGUm",
        "outputId": "f9ece88e-bc3c-4002-d890-96a967fe9e97"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the Features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit training data\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "\n",
        "# fitting the test data\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "NGbsfcOqPRGL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "r2jViL1vPaZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize Modelling\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# prediction\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALD7ZakcPUYF",
        "outputId": "c6faebdf-4c57-4d47-9ed3-e1024fcab63d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train multiple algorithms for selection of which is best\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "  model.fit(x_train, y_train)\n",
        "  y_pred = model.predict(x_test)\n",
        "  print(f\"{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eUk5FXJPY6u",
        "outputId": "19879528-57ff-40fb-b8ed-a7f9dccb0b4b"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a confusion matrices to see false negative made\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
        "\n",
        "for ax, (name, model) in zip(axes, models.items()):\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(ax=ax, cmap=plt.cm.Blues, colorbar=False)\n",
        "    ax.set_title(name)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "8xbaDO8APnPB",
        "outputId": "b0a14f67-8154-444a-a518-639fc2c37a90"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Several classification algorithms were implemented to predict the breast cancer diagnosis, including Logistic Regression, K-Nearest Neighbors (KNN), Random Forest, Support Vector Machine (SVM) and Gradient Boosting.\n",
        "\n",
        "The dataset was split into training and testing subsets to ensure fair performance evaluation. Each model was trained on the training set and then used to predict outcomes on the test set. Performance metrics such as accuracy, precision, recall, and F1-score were calculated, with special emphasis on recall for the malignant class to reduce the risk of false negatives.\n",
        "\n",
        "To visually compare performance, confusion matrices for all models were plotted side-by-side, allowing for quick identification of strengths and weaknesses across algorithms."
      ],
      "metadata": {
        "id": "kxfKCdoDP0ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
        "grid.fit(x_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "best_svm = grid.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2dOma_5P1ti",
        "outputId": "c391ea85-b36e-4b87-e308-cf8301d34cb3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Tuning and Results\n",
        "To enhance model performance, GridSearchCV was applied to tune the SVM hyperparameters. The search explored different values of C, gamma, and kernel types. The optimal parameters found were:\n",
        "\n",
        "C: 100\n",
        "\n",
        "Gamma: 0.001\n",
        "\n",
        "Kernel: RBF\n",
        "\n",
        "The model was retrained using these parameters and evaluated on the test set."
      ],
      "metadata": {
        "id": "lhRpYE0OQAcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain SVM with best parameters\n",
        "best_svm = SVC(C=100, gamma=0.001, kernel='rbf', probability=True)\n",
        "best_svm.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "R3JeuC1aP4k3",
        "outputId": "1e18345e-ed88-45c2-e817-c669b3f7d078"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "y_pred = best_svm.predict(x_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgjViHFLQDtv",
        "outputId": "29e4bd15-deff-4875-fb15-f611eac36a8b"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Metrics\n",
        "The tuned model achieved:\n",
        "\n",
        "Accuracy: 98%\n",
        "\n",
        "Precision (Benign): 97% — 97% of the cases predicted as benign were actually benign.\n",
        "\n",
        "Recall (Benign): 100% — All benign cases were correctly identified.\n",
        "\n",
        "Precision (Malignant): 100% — Every malignant prediction was truly malignant.\n",
        "\n",
        "Recall (Malignant): 95% — The model correctly identified 95% of malignant cases.\n",
        "\n",
        "This indicates that the model is highly accurate and balanced in identifying both benign and malignant tumors."
      ],
      "metadata": {
        "id": "2eXU2n1AQKtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Visualization\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=best_svm.classes_, yticklabels=best_svm.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Tuned SVM')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "0C9n_pv5QHb4",
        "outputId": "ec5f9009-9883-46d8-c3e9-0478e96ae52b"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix Insights\n",
        "\n",
        "The confusion matrix shows:\n",
        "\n",
        "* 71 benign cases were all correctly classified (no false negatives for benign).\n",
        "\n",
        "* 43 malignant cases had 2 false negatives, meaning they were misclassified as benign.\n",
        "\n",
        "While the false negative count is small, in medical diagnosis, even a single false negative can be critical, as it means a malignant case was missed. This highlights a possible area for further improvement, such as experimenting with different kernels, cost-sensitive learning, or ensemble methods."
      ],
      "metadata": {
        "id": "5KnTNm3RQSVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get probability scores for ROC\n",
        "best_svm = SVC(C=100, gamma=0.001, kernel='rbf', probability=True)\n",
        "best_svm.fit(x_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_proba= best_svm.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.3f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random classifier\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Tuned SVM')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "print(\"AUC Score:\", auc_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "kpUfXEKFQN9U",
        "outputId": "d4f9ded2-7d5f-483d-af30-708971aa474c"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To further validate the model, the Receiver Operating Characteristic (ROC) curve and Area Under the Curve (AUC) were computed. The resulting AUC score of 0.997 indicates that the model can distinguish between malignant and benign cases with 99.7% probability, even when the classification threshold is varied. The ROC curve’s close alignment with the top-left corner demonstrates consistently strong sensitivity and specificity across all thresholds, confirming the model’s exceptional generalization capability."
      ],
      "metadata": {
        "id": "sg2y981oQbnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion and Recommendations\n",
        "\n",
        "The tuned Support Vector Machine model demonstrated strong classification performance in distinguishing malignant from benign breast tumors, supported by a high ROC-AUC score and balanced confusion matrix outcomes. The integration of SHAP interpretability confirmed that the model’s most influential features—particularly concave points_mean, concavity_mean, and texture_worst—are consistent with known medical indicators of malignancy.\n",
        "\n",
        "Given the high accuracy and interpretability, this model shows potential as a decision-support tool for clinicians. However, before deployment in a real-world clinical environment, the following steps are recommended:\n",
        "\n",
        "External Validation – Test the model on larger, multi-center datasets to confirm its generalizability across different populations and imaging conditions.\n",
        "\n",
        "Integration with Clinical Workflows – Develop a user-friendly interface that allows radiologists and oncologists to interact with predictions and explanations in real time.\n",
        "\n",
        "Bias and Error Analysis – Investigate any demographic or technical biases in the dataset to ensure equitable performance across patient groups.\n",
        "\n",
        "Periodic Retraining – Implement mechanisms to update the model as new medical data becomes available, maintaining relevance and accuracy.\n",
        "\n",
        "By combining robust predictive accuracy with interpretable outputs, the model offers a promising foundation for improving early detection and reducing diagnostic errors in breast cancer screening. Future work should focus on enhancing dataset diversity, incorporating additional imaging modalities, and evaluating the tool’s impact in prospective clinical trials."
      ],
      "metadata": {
        "id": "D0JzSNgFQ9rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import shap\n",
        "\n",
        "# 1. Save the trained SVM model\n",
        "# Ensure 'best_svm' is the name of your final trained model variable\n",
        "joblib.dump(best_svm, 'svm_model.joblib')\n",
        "\n",
        "# 2. Save the scaler\n",
        "# The scaler is crucial because new input must be scaled the same way as the training data\n",
        "# Ensure 'scaler' is the name of your scaler variable\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# 3. Save the feature names for the UI labels\n",
        "# 'bc' should be your initial dataframe before dropping the target\n",
        "feature_names = bc.drop(columns=['diagnosis']).columns.tolist()\n",
        "joblib.dump(feature_names, 'feature_names.joblib')\n",
        "\n",
        "# 4. Create and save a SHAP data summary for explaining predictions\n",
        "# We use a small, representative sample of the training data ('x_train') for the SHAP explainer\n",
        "shap_summary = shap.kmeans(x_train, 10) # Using 10 summary points\n",
        "joblib.dump(shap_summary, 'shap_data.joblib')\n",
        "\n",
        "print(\"Model, scaler, feature names, and SHAP data have been saved successfully!\")\n",
        "\n",
        "# --- 3. DEFINE THE PREDICTION FUNCTION ---\n",
        "\n",
        "# This function will take user inputs, process them, and return the results\n",
        "def predict_cancer(*feature_values):\n",
        "    try:\n",
        "        # Convert the 30 input values into a NumPy array\n",
        "        input_data = np.array([float(val) if val is not None else 0 for val in feature_values]).reshape(1, -1)\n",
        "    except (ValueError, TypeError):\n",
        "        return \"Error\", \"Invalid input. Please ensure all 30 fields are filled with numbers.\", \"\", \"\"\n",
        "\n",
        "    # Scale the input data using the loaded scaler\n",
        "    scaled_data = scaler.transform(input_data)\n",
        "\n",
        "    # --- GET PREDICTION AND CONFIDENCE SCORE ---\n",
        "    prediction_proba = best_svm.predict_proba(scaled_data)[0]\n",
        "    prediction = best_svm.predict(scaled_data)[0]\n",
        "\n",
        "    if prediction == 0:\n",
        "        diagnosis = \"Benign\"\n",
        "        confidence_score = f\"{prediction_proba[0] * 100:.2f}%\"\n",
        "    else:\n",
        "        diagnosis = \"Malignant\"\n",
        "        confidence_score = f\"{prediction_proba[1] * 100:.2f}%\"\n",
        "\n",
        "    # --- GET TOP CONTRIBUTING FEATURES USING SHAP ---\n",
        "    explainer = shap.KernelExplainer(best_svm.predict_proba, shap_summary)\n",
        "    shap_values = explainer.shap_values(scaled_data)[1] # Get values for the \"Malignant\" class\n",
        "\n",
        "    # Create a DataFrame for easy analysis\n",
        "    feature_shap_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'shap_value': abs(shap_values)\n",
        "    })\n",
        "\n",
        "    # Get the top 3 features with the highest impact\n",
        "    top_features_df = feature_shap_df.sort_values(by='shap_value', ascending=False).head(3)\n",
        "    top_features = \"\\n\".join(top_features_df['feature'].tolist())\n",
        "\n",
        "    # --- GENERATE THE EXPLANATORY NOTE ---\n",
        "    if diagnosis == \"Benign\":\n",
        "        note = \"The model predicts the tumor is **Benign**. This means it is likely non-cancerous. This prediction is based on the diagnostic features provided.\"\n",
        "    else:\n",
        "        note = \"The model predicts the tumor is **Malignant**. This indicates a high likelihood of being cancerous. Please consult a medical professional for confirmation and further steps.\"\n",
        "\n",
        "    return diagnosis, confidence_score, top_features, note\n",
        "\n",
        "\n",
        "# --- 4. CREATE THE GRADIO INTERFACE ---\n",
        "\n",
        "# Create a list of input components for the 30 features\n",
        "input_components = [gr.Number(label=name) for name in feature_names]\n",
        "\n",
        "# Create the user interface\n",
        "app = gr.Interface(\n",
        "    fn=predict_cancer,\n",
        "    inputs=input_components,\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Prediction\"),\n",
        "        gr.Textbox(label=\"Confidence Score\"),\n",
        "        gr.Textbox(label=\"Top 3 Contributing Features\"),\n",
        "        gr.Markdown(label=\"What This Prediction Means\")\n",
        "    ],\n",
        "    title=\"Breast Cancer Diagnosis Predictor\",\n",
        "    description=\"Enter the 30 diagnostic feature values below to get a prediction from the SVM model.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# --- 5. LAUNCH THE APP ---\n",
        "app.launch(share=True)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
